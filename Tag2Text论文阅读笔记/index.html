<!DOCTYPE html>
<html class="writer-html5" lang="zh_CN" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="Desheng Wang" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>【2】Tag2Text论文阅读笔记 - 机器学习论文阅读笔记</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "\u30102\u3011Tag2Text\u8bba\u6587\u9605\u8bfb\u7b14\u8bb0";
        var mkdocs_page_input_path = "Tag2Text\u8bba\u6587\u9605\u8bfb\u7b14\u8bb0.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/yaml.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> 机器学习论文阅读笔记
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">三、大语言模型篇</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../Language_Model%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">【1】Language Model语言模型</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../LLaMa%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">【2】LLaMa论文阅读笔记</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">二、多模态篇</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../BLIP%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">【1】BLIP论文阅读笔记</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="./">【2】Tag2Text论文阅读笔记</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#0-abstract">0. Abstract</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#1-introduction">1. Introduction</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#2-related-work">2. Related Work</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#3-approach">3. Approach</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#31-overview-framework">3.1 Overview Framework</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#32-mining-tags-from-texts">3.2 Mining Tags from Texts</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#33-tag2text-pre-training">3.3 Tag2Text Pre-training</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#34-tag-guided-vl-tasks">3.4 Tag-Guided V+L Tasks</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#4-experiment">4. Experiment</a>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../Recognize_Anything%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">【3】Recognize Anything论文阅读笔记</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">一、工具篇</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../mkdocs%E5%B8%AE%E5%8A%A9/">【1】mkdocs帮助</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="..">【2】深度学习工具</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">机器学习论文阅读笔记</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">二、多模态篇</li>
      <li class="breadcrumb-item active">【2】Tag2Text论文阅读笔记</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="tag2text">Tag2Text<a class="headerlink" href="#tag2text" title="Permanent link">&para;</a></h1>
<ul>
<li>Paper:《Tag2Text: Guiding Vision-Language Model via Image Tagging》</li>
</ul>
<h2 id="0-abstract">0. Abstract<a class="headerlink" href="#0-abstract" title="Permanent link">&para;</a></h2>
<ul>
<li>tag2text:将图片打标签引入到VLP模型中，以指导模型可以学习<strong>视觉-语言</strong>（visual-linguistic）特征表示；</li>
<li>prior works：人工标注tags，或者，通过一个受限的探测器去探测tags；</li>
<li><strong>generation-based</strong> task and <strong>alignment-based</strong> tasks；</li>
</ul>
<h2 id="1-introduction">1. Introduction<a class="headerlink" href="#1-introduction" title="Permanent link">&para;</a></h2>
<ul>
<li>随着大规模图文image-text对的数据获得变得更方便，近期的大多数工作主要聚焦于大规模数据中，利用transformer-based方法去解决对比学习或者生成式学习；</li>
<li>Prior approaches introduce the use of object tags as anchor points to ease(减轻、放松) the learning of semantic alignments between images and texts. these approaches rely on obsolete（退化的） detector-based VLP frameworks, which employ off-the-shelf object detectors to extract image features.Prior approaches遵循的是基于检测器的范式。通过使用目标 tags 作为锚点来简化图片和文本之间的语义对。这些方法通过一个检测器来提取图片特征，并送进多模态交互模块中进行学习。这种情况下检测器参数都是冻住的（如果梯度优化检测性能就会骤降），所以检测器不能优化，导致检测器性能会制约视觉-语言特征的学习。</li>
<li>Prior approaches limitation：利用VLP（vision language pretrain）去实现目标检测能力，必须frozen detector-based models，因此就限制了vision language 模型的能力。这样使得加大大量昂贵的标注数据变的不够有效。另外导致模型的参数量增加，且推理运行计算时长也增加了。</li>
<li>对视觉语言模型（Vision-Language Models）引入图片标记（images tagging）任务来指导模型学习更好的视觉-语言特征。图片标记，类似于给一个图片打个多个与图片有关的label，有点像多label分类。</li>
<li><strong>two crucial perspectives：</strong><ul>
<li><strong>Data数据问题</strong>：引入了图片标记（image tagging）就需要构造图片中的tags 作为 label 用于训练。因为 image-text-pair数据很丰富，所以作者对image-text-pair进行自动化文本语义解析，从而从text中获取图片的tags。这样，图像tags能提供了图像和文本之间更好的桥梁，因为解析的标记类别更加多样化，同时比目标检测的object更丰富，有例如场景、属性、动作等。</li>
<li><strong>Architecture</strong>：在original image encoder后面增加了recognition head，促使模型可以end-to-end高效预训练，更少的参数，更好性能提升。</li>
</ul>
</li>
<li>Object detector 与 Image tagging对比： <img alt="" src="../pic/tag2text/tag2text1.png" /></li>
<li><strong>generation-based task</strong>：将训练任务变成image-tag-text生成任务。</li>
<li><strong>alignment-based task</strong>：将标签和生成的text对齐。</li>
</ul>
<h2 id="2-related-work">2. Related Work<a class="headerlink" href="#2-related-work" title="Permanent link">&para;</a></h2>
<ul>
<li>Image Tagging：一种多标签学习，是一种基础视觉任务。</li>
<li>近期的研究表明，transformer-based的可以更好引入视觉特征，且健全的损失函数可以解决样本缺失和样本不平衡的问题。</li>
<li>目前大多数的多标签学习样本都是基于人工标注样本，且劳动力敏感型且很难加大数据量的规模。</li>
<li>本文的方案可以从文本语义特征解析出并高效获得image tags和构建大规模的image tag的数据集，包含3429个常规类目，从而获得了更加高级的tag识别能力。</li>
</ul>
<h2 id="3-approach">3. Approach<a class="headerlink" href="#3-approach" title="Permanent link">&para;</a></h2>
<h3 id="31-overview-framework">3.1 Overview Framework<a class="headerlink" href="#31-overview-framework" title="Permanent link">&para;</a></h3>
<ul>
<li>总体框架图： <img alt="" src="../pic/tag2text/tag2text2.png" /></li>
<li>核心关键在于如何从大规模image-textpairs中，利用图片的text挖掘image tags；</li>
</ul>
<h3 id="32-mining-tags-from-texts">3.2 Mining Tags from Texts<a class="headerlink" href="#32-mining-tags-from-texts" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>Text Semantic Parser</strong>：image-text对的text--&gt;image tags；</p>
<ul>
<li>利用<strong>dependency tree句子依存关系树</strong>挖掘出<em>entities (= head + modifier)</em>和<em>relationships</em>；</li>
<li>tags={objects，scenes，attributes，actions}</li>
<li>head--&gt;object/scene</li>
<li>modifier--&gt;attribute</li>
<li>relationship--&gt;action</li>
</ul>
</li>
<li>
<p><strong>Tag Category System Construction</strong>：原则=tags越是频繁出现，那么它越重要。</p>
<ul>
<li>Text Sematic parser--&gt;4 million(4百万)--&gt;按照频率过滤--&gt;5000个最频繁出现的tags--&gt;人工过滤和reveiw--&gt;3429个常规类目tags。 </li>
</ul>
</li>
<li>个人观点：有点人工，主观性强。</li>
</ul>
<h3 id="33-tag2text-pre-training">3.3 Tag2Text Pre-training<a class="headerlink" href="#33-tag2text-pre-training" title="Permanent link">&para;</a></h3>
<ul>
<li>多任务的预训练模型：Tagging，Generation，Alignment。</li>
<li><strong>Image Tagging</strong>：参考了论文《Query2Label-A Simple Transformer Way to Multi-Label Classification》Query2Label中的多label分类transformer decoder（用法如下图），同时为了避免解析的tags中有某些对应图片tag的缺失、正负样本的不平衡，使用了Asymmetirc Loss（ASL）。<img alt="" src="../pic/tag2text/tag2text3.png" /></li>
<li><strong>Image-Tag-Text Generation</strong>：参考了标准的transformer的encoder-decoder框架，tags与text都经过 tokenizer+embeding matrix 映射为embeding，然后 tags embeding（image tags随机乱序重新排序，防止顺序影响学习）与 image embedding(features）一起送入encoder，再经过decoder解码。输出与text embedding进行loss计算，采用单向语言模型的Loss，以自回归的方式拟合文本最大似然估计。<ul>
<li>主体思想：相当于用tag指导image生成text；这种方式的好处是产生的文本更加便于理解和强可控性。</li>
<li>示意方式如下图所示，前人的想法要么是（a）要么是（b），但是本文的思想是（c） <img alt="" src="../pic/tag2text/tag2text4.png" /></li>
<li>个人看法，我觉得（b）方法可能会成为未来的主流技术方案，一步到位生成结果。</li>
</ul>
</li>
<li><strong>Image-Text Alignment</strong>：判断image和text是否对齐。在框架中，通过额外引入一个image-text alignment encoder来实现对齐。用粗粒度的 Image-Text Contrastive(ITC) Loss 和 细粒度的 Image-Text Matching(ITM) Loss 分别进行学习，这里参考了BLIP的技术方案。且在ITC阶段获得更高similarity的负样本会被更大概率被选择进入ITM阶段，目标去处理更加难的部分。 <img alt="" src="../pic/tag2text/tag2text5.png" /></li>
</ul>
<h3 id="34-tag-guided-vl-tasks">3.4 Tag-Guided V+L Tasks<a class="headerlink" href="#34-tag-guided-vl-tasks" title="Permanent link">&para;</a></h3>
<ul>
<li>从标题就可以看出，利用tags去指导并提升各种vision+language任务，如下图各类任务所示的处理办法。</li>
<li>Multi-Label Recognition任务</li>
<li>Image Captioning任务</li>
<li>Visual Question Answering任务</li>
<li>Image-Text Retrieval任务</li>
</ul>
<p><img alt="" src="../pic/tag2text/tag2text6.png" /></p>
<h2 id="4-experiment">4. Experiment<a class="headerlink" href="#4-experiment" title="Permanent link">&para;</a></h2>
<ul>
<li>预训练数据组成：4M（人工标注数据+web数据）+14M（人工标注数据+web数据+带噪声的web数据）<img alt="" src="../pic/tag2text/tag2text7.png" /></li>
<li>The models are pre-trained for 20 epochs with the batch size of 960 on 8 NVIDIA A100 GPUs。</li>
<li>The input images are resized to 224 × 224 uniformly during the pre-training stage.</li>
</ul>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../BLIP%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" class="btn btn-neutral float-left" title="【1】BLIP论文阅读笔记"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../Recognize_Anything%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" class="btn btn-neutral float-right" title="【3】Recognize Anything论文阅读笔记">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
      <p>2023, Desheng Wang</p>
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../BLIP%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../Recognize_Anything%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
